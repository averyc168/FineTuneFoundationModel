{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LoRA\n",
    "* Model: Bert-base-uncased\n",
    "* Evaluation approach: Trainer.evaluate() and compute_metrics\n",
    "* Fine-tuning dataset: Yelp/yelp_review_full "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, DataCollatorWithPadding, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForCausalLM, TaskType\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "### initialize tokenizer and tokenize_function\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding = \"max_length\", truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 4000\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get the dataset for training and evaluating\n",
    "train_ds, eval_ds = load_dataset(\"Yelp/yelp_review_full\", split=[\"train[:4000]\", \"test[:1000]\"]) \n",
    "\n",
    "# get the labels of the dataset and put them in dictionaries\n",
    "labels = train_ds.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "# splitting the dataset into train and evaluation and then tokenizing them\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "eval_ds = eval_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# output data from both training and evaluation data sets\n",
    "print(train_ds)\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if data looks right and matches with the dataset page https://huggingface.co/datasets/PolyAI/banking77\n",
    "print(train_ds[10])\n",
    "print(eval_ds[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### getting the pretrained model\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 5,\n",
    "                                                           label2id=label2id, id2label=id2label)\n",
    "\n",
    "# freeze all parameters of the base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# creating a compute_metrics function to calculate how accurate the model is during training\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6740609407424927,\n",
       " 'eval_accuracy': 0.234,\n",
       " 'eval_runtime': 33.3252,\n",
       " 'eval_samples_per_second': 30.007,\n",
       " 'eval_steps_per_second': 1.89}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### training the pre-trained model to the dataset and evaluating its performance\n",
    "\n",
    "# setting its arguments\n",
    "training_args = TrainingArguments(output_dir= \"./results\", \n",
    "                                  per_device_train_batch_size= 16, per_device_eval_batch_size= 16, \n",
    "                                  learning_rate= 2e-5, num_train_epochs= 0, weight_decay = 0.01,\n",
    "                                  evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "                                  load_best_model_at_end= True,)\n",
    "\n",
    "trainer = Trainer(model = model, args = training_args, train_dataset= train_ds, eval_dataset= eval_ds,\n",
    "                  tokenizer=tokenizer, data_collator= DataCollatorWithPadding(tokenizer=tokenizer), \n",
    "                  compute_metrics=compute_metrics,)\n",
    "\n",
    "# get evaluation stats\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up different LoraConfigs\n",
    "config = LoraConfig(task_type= TaskType.SEQ_CLS, r = 1,\n",
    "                    lora_alpha= 1, lora_dropout= 0.01,\n",
    "                    bias = \"none\")\n",
    "\n",
    "# creating the base model before lora and peft configurations\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 5, \n",
    "                                             label2id=label2id, id2label=id2label)\n",
    "\n",
    "# unfreeze all parameters of the base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d40fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the format of the train and evaluation dataset to contain specific columns\n",
    "# for the training and evaluating\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "eval_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "lora_model = get_peft_model(model, config)      # original lora model that will be saved\n",
    "\n",
    "# see the trainable parameters of each \n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "### training the pre-trained model to the dataset and evaluating its performance\n",
    "\n",
    "# setting its arguments\n",
    "peft_training_args = TrainingArguments(output_dir= \"./peft_test_trainer\",\n",
    "                                  per_device_train_batch_size= 16, per_device_eval_batch_size= 16, \n",
    "                                  learning_rate= 2e-5, num_train_epochs= 5, weight_decay= 0.01,\n",
    "                                  evaluation_strategy= \"epoch\", save_strategy= \"epoch\",\n",
    "                                  load_best_model_at_end= True, logging_dir='./logs',)\n",
    "\n",
    "peft_trainer = Trainer(model = lora_model, args = peft_training_args, train_dataset= train_ds, eval_dataset= eval_ds,\n",
    "                       tokenizer = tokenizer, data_collator = DataCollatorWithPadding(tokenizer=tokenizer), \n",
    "                       compute_metrics=compute_metrics,)\n",
    "\n",
    "peft_trainer.train()\n",
    "\n",
    "lora_model.save_pretrained(\"peft-bert-lora-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# load the base model first\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# load the saved peft configurations from the directory we saved above\n",
    "peft_model_id = \"peft-bert-lora-model\"\n",
    "\n",
    "# create model with the peft configurations\n",
    "new_peft_model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "\n",
    "# keep the peft model with the new weights\n",
    "new_peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eee544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model\n",
    "new_peft_model.eval()\n",
    "\n",
    "### inferencing with the model\n",
    "inputs = tokenizer(\"When can I expect my new card to arrive?\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = new_peft_model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "    print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extra lora_configs\n",
    "config2 = LoraConfig(task_type= TaskType.SEQ_CLS, r = 4, lora_alpha= 16, lora_dropout= 0.2)\n",
    "config3 = LoraConfig(task_type= TaskType.SEQ_CLS, r = 8, lora_alpha= 32, lora_dropout= 0.1)\n",
    "\n",
    "lora_model2 = get_peft_model(model, config2)\n",
    "lora_model3 = get_peft_model(model, config3)\n",
    "\n",
    "lora_model2.print_trainable_parameters()\n",
    "lora_model3.print_trainable_parameters()\n",
    "\n",
    "### training the other two lora models and evaluating their results\n",
    "trainer2 = Trainer(model = lora_model2, \n",
    "                   args = TrainingArguments(output_dir= \"./peft_test_trainer2\",\n",
    "                                  per_device_train_batch_size= 16, \n",
    "                                  per_device_eval_batch_size= 16, \n",
    "                                  learning_rate= 2e-5, \n",
    "                                  num_train_epochs= 5, \n",
    "                                  weight_decay= 0.01,\n",
    "                                  evaluation_strategy= \"epoch\", \n",
    "                                  save_strategy= \"epoch\",\n",
    "                                  load_best_model_at_end= True,\n",
    "                                  logging_dir='./logs2',\n",
    "                    ), \n",
    "                   train_dataset= train_ds, \n",
    "                   eval_dataset= eval_ds,\n",
    "                   tokenizer = tokenizer, \n",
    "                   data_collator= DataCollatorWithPadding(tokenizer=tokenizer), \n",
    "                   compute_metrics=compute_metrics,)\n",
    "trainer2.train()\n",
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer3 = Trainer(model = lora_model3, \n",
    "                   args = TrainingArguments(output_dir= \"./peft_test_trainer3\",\n",
    "                                  per_device_train_batch_size= 16, \n",
    "                                  per_device_eval_batch_size= 16, \n",
    "                                  learning_rate= 2e-5, \n",
    "                                  num_train_epochs= 5, \n",
    "                                  weight_decay= 0.01,\n",
    "                                  evaluation_strategy= \"epoch\", \n",
    "                                  save_strategy= \"epoch\",\n",
    "                                  load_best_model_at_end= True,\n",
    "                                  logging_dir='./logs3',\n",
    "                    ),  \n",
    "                   train_dataset= train_ds, \n",
    "                   eval_dataset= eval_ds,\n",
    "                   tokenizer = tokenizer, \n",
    "                   data_collator= DataCollatorWithPadding(tokenizer=tokenizer), \n",
    "                   compute_metrics=compute_metrics,)\n",
    "trainer3.train()\n",
    "trainer3.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
